{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условие: Задача состоит в модификации кода градиентного спуска для задачи регрессии (ноутбук лекции - Gradient_descent.ipynb). Необходимо, чтобы ваш градиентный спуск мог решать задачи классификации, а именно линейной классификации и логистической регрессии.\n",
    "На всякий случай напомню, что код будет разный, поэтому жду от вас две функции градиентного спуска.\n",
    "Чтобы решить задачи, обратите внимание на пункт “Принцип максимального правдоподобия” статьи http://www.machinelearning.ru/wiki/images/6/68/voron-ML-Lin.pdf . Там находится ответ на вопрос “какая функция потерь”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate a data\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random.sample(range(1, 1000), 100)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# simple class determ function. odd/even\n",
    "data['guess'] = data[0].apply(lambda x: x % 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model crashed while trying to predict this\n",
    "# was predictable, because it is not linear function\n",
    "# let's do it another way\n",
    "\n",
    "data = random.sample(range(1, 1000), 100)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "def if_more(x):\n",
    "    if x > 500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# simple class determ function. odd/even\n",
    "data['guess'] = data[0].apply(if_more)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only if you ran the one of previous two cells\n",
    "x = data[[0,'w']]\n",
    "x = x.to_numpy()\n",
    "y = data['guess']\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_class(alpha, x, y, numIterations):\n",
    "    \"\"\"\n",
    "    Linear gradient classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x.shape[0] \n",
    "    \n",
    "    # add ones for delta\n",
    "    x = np.c_[ np.ones(m), x]\n",
    "    \n",
    "    n = x.shape[1]\n",
    "    \n",
    "    theta = np.ones(n) # model weights\n",
    "    x_transpose = x.transpose()\n",
    "    \n",
    "    print(f\"Initializing gradient search. M is {m}. N is {n}\")\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        hypothesis = np.dot(x, theta) # матричное произведение\n",
    "        \n",
    "        loss = hypothesis - y\n",
    "        J = np.sum(loss ** 2) / (2 * m)  # функция потерь\n",
    "        \n",
    "        #print( \"iter %s | J: %.3f\" % (iter, J) )\n",
    "        #print(theta)\n",
    "        \n",
    "        gradient = np.dot(x_transpose, loss) / m         \n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    print('Model weights:')\n",
    "    print(theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuck it, take ready dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "prepare_data = pd.DataFrame(iris.data)\n",
    "prepare_data['class'] = iris.target\n",
    "\n",
    "# remove third class\n",
    "prepare_data = prepare_data[prepare_data['class'] != 2] \n",
    "\n",
    "x = prepare_data.drop('class', axis=1)\n",
    "x = x.to_numpy()\n",
    "y = prepare_data['class']\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing gradient search. M is 100. N is 5\n",
      "Model weights:\n",
      "[ 0.74630389 -0.25887133  0.04055461  0.17711531  0.68463828]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "theta = gradient_descent_class(alpha, x, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>class</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.022260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3  class   predict\n",
       "0   5.1  3.5  1.4  0.2      0 -0.047110\n",
       "1   4.9  3.0  1.4  0.2      0 -0.015613\n",
       "2   4.7  3.2  1.3  0.2      0  0.026561\n",
       "3   4.6  3.1  1.5  0.2      0  0.083816\n",
       "4   5.0  3.6  1.4  0.2      0 -0.017167\n",
       "..  ...  ...  ...  ...    ...       ...\n",
       "95  5.7  3.0  4.2  1.2      1  0.957851\n",
       "96  5.7  2.9  4.2  1.3      1  1.022260\n",
       "97  6.2  2.9  4.3  1.3      1  0.910536\n",
       "98  5.1  2.5  3.0  1.1      1  0.811895\n",
       "99  5.7  2.8  4.1  1.3      1  1.000493\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_prediction(row):\n",
    "    global theta\n",
    "    return theta[0] + theta[1]*row[0] + theta[2]*row[1] + theta[3]*row[2] + theta[4]*row[3]\n",
    "\n",
    "results = pd.DataFrame(x)\n",
    "results['class'] = y\n",
    "results['predict'] = results.apply(class_prediction, axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.01, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.SGDRegressor( alpha = 0.01, max_iter = 1000 )\n",
    "\n",
    "model.fit( x, y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['control'] = results.apply(lambda x: model.intercept_ + model.coef_[0]*x[0] \n",
    "                                   + model.coef_[1]*x[1] + model.coef_[2]*x[2] + model.coef_[3]*x[3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>class</th>\n",
       "      <th>predict</th>\n",
       "      <th>control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047110</td>\n",
       "      <td>[0.003218576493438416]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015613</td>\n",
       "      <td>[0.06359676277200803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>[0.009566637277169596]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083816</td>\n",
       "      <td>[0.07356866045333514]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017167</td>\n",
       "      <td>[-0.01062542245016547]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957851</td>\n",
       "      <td>[0.9203151735683595]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>[0.9437994484058024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910536</td>\n",
       "      <td>[0.9764571534701828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811895</td>\n",
       "      <td>[0.648631975204771]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000493</td>\n",
       "      <td>[0.9300382042504255]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3  class   predict                 control\n",
       "0   5.1  3.5  1.4  0.2      0 -0.047110  [0.003218576493438416]\n",
       "1   4.9  3.0  1.4  0.2      0 -0.015613   [0.06359676277200803]\n",
       "2   4.7  3.2  1.3  0.2      0  0.026561  [0.009566637277169596]\n",
       "3   4.6  3.1  1.5  0.2      0  0.083816   [0.07356866045333514]\n",
       "4   5.0  3.6  1.4  0.2      0 -0.017167  [-0.01062542245016547]\n",
       "..  ...  ...  ...  ...    ...       ...                     ...\n",
       "95  5.7  3.0  4.2  1.2      1  0.957851    [0.9203151735683595]\n",
       "96  5.7  2.9  4.2  1.3      1  1.022260    [0.9437994484058024]\n",
       "97  6.2  2.9  4.3  1.3      1  0.910536    [0.9764571534701828]\n",
       "98  5.1  2.5  3.0  1.1      1  0.811895     [0.648631975204771]\n",
       "99  5.7  2.8  4.1  1.3      1  1.000493    [0.9300382042504255]\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "http://neerc.ifmo.ru/wiki/index.php?title=%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdc_log(alpha, x, y, numIterations):\n",
    "    \"\"\"\n",
    "    Logistic gradient classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    m = x.shape[0] \n",
    "    \n",
    "    # add ones for delta\n",
    "    x = np.c_[ np.ones(m), x]\n",
    "    \n",
    "    n = x.shape[1]\n",
    "    \n",
    "    theta = np.ones(n) # model weights\n",
    "    x_transpose = x.transpose()\n",
    "    \n",
    "    print(f\"Initializing gradient search. M is {m}. N is {n}\")\n",
    "    \n",
    "    for iter in range( 0, numIterations ):\n",
    "        hypothesis = np.dot(x, theta) # матричное произведение\n",
    "        \n",
    "        loss = hypothesis - y\n",
    "        J = np.sum(loss ** 2) / (2 * m)  # функция потерь\n",
    "        \n",
    "        #print( \"iter %s | J: %.3f\" % (iter, J) )\n",
    "        #print(theta)\n",
    "        \n",
    "        gradient = np.dot(x_transpose, loss) / m\n",
    "        # \n",
    "        theta = theta - alpha * gradient  # update\n",
    "    \n",
    "    print('Model weights:')\n",
    "    print(theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "theta = gradient_descent_class(alpha, x, y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results by standart libraries \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "model = clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>class</th>\n",
       "      <th>predict</th>\n",
       "      <th>control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047110</td>\n",
       "      <td>[-4.115819625002858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015613</td>\n",
       "      <td>[-3.750408524782121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026561</td>\n",
       "      <td>[-4.250724679059565]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083816</td>\n",
       "      <td>[-3.7423652160371637]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017167</td>\n",
       "      <td>[-4.250552919169594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957851</td>\n",
       "      <td>[4.027998798868048]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>[4.214928374027647]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910536</td>\n",
       "      <td>[4.665960347552295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811895</td>\n",
       "      <td>[1.3508364191876232]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000493</td>\n",
       "      <td>[4.074775620734281]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3  class   predict                control\n",
       "0   5.1  3.5  1.4  0.2      0 -0.047110   [-4.115819625002858]\n",
       "1   4.9  3.0  1.4  0.2      0 -0.015613   [-3.750408524782121]\n",
       "2   4.7  3.2  1.3  0.2      0  0.026561   [-4.250724679059565]\n",
       "3   4.6  3.1  1.5  0.2      0  0.083816  [-3.7423652160371637]\n",
       "4   5.0  3.6  1.4  0.2      0 -0.017167   [-4.250552919169594]\n",
       "..  ...  ...  ...  ...    ...       ...                    ...\n",
       "95  5.7  3.0  4.2  1.2      1  0.957851    [4.027998798868048]\n",
       "96  5.7  2.9  4.2  1.3      1  1.022260    [4.214928374027647]\n",
       "97  6.2  2.9  4.3  1.3      1  0.910536    [4.665960347552295]\n",
       "98  5.1  2.5  3.0  1.1      1  0.811895   [1.3508364191876232]\n",
       "99  5.7  2.8  4.1  1.3      1  1.000493    [4.074775620734281]\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = pd.DataFrame(x)\n",
    "logr['class'] = y\n",
    "logr['predict'] = logr.apply(lambda x: theta[0] + theta[1]*x[0] + theta[2]*x[1] + theta[3]*x[2] + theta[4]*x[3], axis=1)\n",
    "logr['control'] = logr.apply(lambda x: model.intercept_ + model.coef_[0][0]*x[0] \n",
    "                                   + model.coef_[0][1]*x[1] + model.coef_[0][2]*x[2] + model.coef_[0][3]*x[3], axis=1)\n",
    "logr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вопросы к предподавателю:\n",
    "* Почему в отличии от линейной модели, логистическая возвращает коэффициенты в двойном листе [ [ ] ] ?\n",
    "* Почему когда я делаю столбик 'control' я получаю значение в листе [x] ?\n",
    "* Нормально ли, что \"вероятности\" принадлежности к тому или иному классу могут принимать как отрицательные значения, так и значения больше 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
